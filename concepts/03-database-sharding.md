# üß© Database Sharding (Fragmenta√ß√£o de Banco de Dados)

## Defini√ß√£o e Vis√£o Geral

Database Sharding √© uma t√©cnica de arquitetura de banco de dados que particiona um banco de dados maior em fragmentos menores, independentes e mais gerenci√°veis chamados "shards". Cada shard √© uma inst√¢ncia de banco de dados independente que armazena um subconjunto espec√≠fico dos dados totais. Todos os shards juntos comp√µem o conjunto completo de dados.

Sharding √© uma forma de particionamento horizontal, onde linhas de uma tabela de banco de dados s√£o armazenadas separadamente, em vez de dividir uma tabela por colunas (particionamento vertical). O objetivo principal √© distribuir a carga de maneira uniforme, melhorar a performance e permitir maior escalabilidade para lidar com o crescimento de dados em grande escala.

## Diagramas

### Vis√£o Geral do Sharding

```mermaid
graph TD
    Client[Cliente] --> Router[Roteador de Consultas]
    Router --> Shard1[Shard 1<br>Usu√°rios A-G]
    Router --> Shard2[Shard 2<br>Usu√°rios H-N]
    Router --> Shard3[Shard 3<br>Usu√°rios O-Z]
    
    style Router fill:#f96,stroke:#333,stroke-width:2px
    style Shard1 fill:#bbf,stroke:#333,stroke-width:1px
    style Shard2 fill:#bbf,stroke:#333,stroke-width:1px
    style Shard3 fill:#bbf,stroke:#333,stroke-width:1px
```

### Estrat√©gias de Sharding

```mermaid
graph LR
    ShardingStrategies[Estrat√©gias de Sharding] --> RangeSharding[Range Sharding]
    ShardingStrategies --> HashSharding[Hash Sharding]
    ShardingStrategies --> GeoSharding[Geo Sharding]
    ShardingStrategies --> DirectorySharding[Directory Sharding]
    
    RangeSharding --> RangeDesc["Divide por intervalos<br>(ex: A-G, H-N, O-Z)"]
    HashSharding --> HashDesc["Usa fun√ß√£o hash<br>na chave de sharding"]
    GeoSharding --> GeoDesc["Baseado em<br>localiza√ß√£o geogr√°fica"]
    DirectorySharding --> DirDesc["Usa lookup table<br>para mapeamento"]
```

### Consultas entre Shards (Cross-Shard Queries)

```mermaid
sequenceDiagram
    participant Client as Cliente
    participant Router as Roteador
    participant Shard1 as Shard 1
    participant Shard2 as Shard 2
    participant Shard3 as Shard 3
    
    Client->>Router: SELECT * FROM users WHERE country IN ('BR', 'US')
    Router->>Shard1: Query para country = 'BR'
    Router->>Shard2: Query para country = 'US'
    Shard1-->>Router: Resultados parciais (BR)
    Shard2-->>Router: Resultados parciais (US)
    Router->>Router: Combina resultados
    Router-->>Client: Resultados completos
```

## Casos de Uso

- **Aplica√ß√µes de alto tr√°fego**: Redes sociais, e-commerce, plataformas de streaming
- **Big Data**: Sistemas de an√°lise que processam petabytes de dados
- **IoT (Internet das Coisas)**: Sistemas que ingerem quantidades massivas de dados de sensores
- **Jogos online**: Separa√ß√£o de jogadores por regi√µes ou servidores
- **SaaS multi-tenant**: Isolamento de dados de diferentes clientes

## Exemplos Pr√°ticos

### Implementa√ß√£o de Sharding com MongoDB

```javascript
// Configura√ß√£o de um cluster sharded no MongoDB
sh.enableSharding("meu_banco_de_dados")

// Definir chave de sharding para uma cole√ß√£o
sh.shardCollection(
    "meu_banco_de_dados.usuarios",
    { "pais": 1 }  // Chave de sharding baseada no pa√≠s
)

// Adicionar tags para distribui√ß√£o geogr√°fica
sh.addShardTag("shard0000", "us")
sh.addShardTag("shard0001", "eu")
sh.addShardTag("shard0002", "asia")

// Definir ranges para as tags
sh.addTagRange(
    "meu_banco_de_dados.usuarios",
    { "pais": "US" },
    { "pais": "UZ" },
    "us"
)

sh.addTagRange(
    "meu_banco_de_dados.usuarios",
    { "pais": "DE" },
    { "pais": "GB" },
    "eu"
)
```

### Sharding com PostgreSQL (usando extens√£o Citus)

```sql
-- Criar tabela distribu√≠da
CREATE TABLE usuarios (
    id bigserial PRIMARY KEY,
    nome text NOT NULL,
    email text NOT NULL,
    pais_codigo char(2)
);

-- Distribuir tabela usando Citus
SELECT create_distributed_table('usuarios', 'pais_codigo');

-- Consulta que ser√° automaticamente roteada para o shard apropriado
SELECT count(*) FROM usuarios WHERE pais_codigo = 'BR';

-- Consulta que precisa consolidar resultados de m√∫ltiplos shards
SELECT pais_codigo, count(*) FROM usuarios GROUP BY pais_codigo;
```

## Pr√≥s e Contras

### Pr√≥s
- **Escalabilidade horizontal**: Facilita a adi√ß√£o de novos n√≥s para acomodar crescimento
- **Performance melhorada**: Consultas s√£o distribu√≠das em m√∫ltiplos n√≥s
- **Melhor localidade de dados**: Os dados podem ser armazenados mais pr√≥ximos dos usu√°rios
- **Isolamento de falhas**: Falhas impactam apenas um shard, n√£o todo o sistema
- **Otimiza√ß√£o de recursos**: Cada shard pode ser otimizado para seu tipo espec√≠fico de dados

### Contras
- **Complexidade operacional**: Aumenta significativamente a complexidade de administra√ß√£o
- **Complexidade de consultas**: Consultas que abrangem m√∫ltiplos shards s√£o mais complexas
- **Desafios de JOIN**: JOINs entre tabelas em diferentes shards s√£o muito custosos
- **Transa√ß√µes distribu√≠das**: Dif√≠cil manter ACID em transa√ß√µes entre shards
- **Rebalanceamento**: Mover dados entre shards pode ser complexo e disruptivo
- **Overhead**: Necessidade de servidores adicionais para gerenciamento

## Melhores Pr√°ticas

1. **Escolha cuidadosamente a chave de sharding**: Deve distribuir uniformemente os dados e minimizar consultas entre shards.

2. **Evite opera√ß√µes entre shards**: Projete seu esquema de dados para minimizar JOINs e transa√ß√µes que atravessam m√∫ltiplos shards.

3. **Implemente uma estrat√©gia de backup consistente**: Garanta que backups sejam coordenados entre todos os shards.

4. **Considere o impacto de rebalanceamento**: Planeje com anteced√™ncia para crescimento e redistribui√ß√£o de dados.

5. **Monitore a distribui√ß√£o de dados**: Verifique regularmente se h√° hot spots (shards sobrecarregados).

6. **Implemente caching adequado**: Reduza a press√£o nos shards com estrat√©gias eficientes de cache.

7. **Teste exaustivamente**: Sharding introduz complexidade; teste todas as opera√ß√µes cr√≠ticas.

8. **Tenha um plano de recupera√ß√£o**: Prepare-se para cen√°rios de falha completa ou parcial de shards.

## Estrat√©gias de Sharding Comuns

### Range Sharding
Divide os dados com base em intervalos de valores.

**Exemplo**: Usu√°rios A-M no Shard 1, N-Z no Shard 2.

**Vantagens**: Eficiente para consultas de intervalo.

**Desvantagens**: Risco de hot spots se a distribui√ß√£o n√£o for uniforme.

### Hash Sharding
Usa uma fun√ß√£o hash aplicada √† chave de sharding.

**Exemplo**: hash(user_id) % n√∫mero_de_shards determina o shard.

**Vantagens**: Distribui√ß√£o uniforme dos dados.

**Desvantagens**: Ineficiente para consultas de intervalo.

### Geo Sharding
Divide por localiza√ß√£o geogr√°fica.

**Exemplo**: Usu√°rios europeus em shards europeus, americanos em shards americanos.

**Vantagens**: Baixa lat√™ncia para usu√°rios.

**Desvantagens**: Complexidade em consultas globais.

### Directory-Based Sharding
Mant√©m um servi√ßo de diret√≥rio que mapeia os dados para os shards.

**Vantagens**: Flexibilidade m√°xima.

**Desvantagens**: O diret√≥rio torna-se um ponto √∫nico de falha.

## Tecnologias que Suportam Sharding

- **NoSQL**: MongoDB, Cassandra, DynamoDB
- **SQL**: MySQL Cluster, PostgreSQL (com Citus), CockroachDB
- **NewSQL**: Google Spanner, VoltDB, TiDB
- **Middleware**: Vitess (MySQL), ProxySQL, ShardingSphere
- **Servi√ßos em Nuvem**: Azure Cosmos DB, Google Cloud Spanner, AWS Aurora

## Refer√™ncias

- Tiwari, S. (2011). Professional NoSQL. Wrox.
- MongoDB. (2023). Sharding. https://docs.mongodb.com/manual/sharding/
- PostgreSQL. (2023). Citus Data Documentation. https://docs.citusdata.com/
- Kleppmann, M. (2017). Designing Data-Intensive Applications. O'Reilly Media.
- AWS. (2023). Sharding with Amazon DynamoDB. https://aws.amazon.com/blogs/database/sharding-with-amazon-dynamodb/
- Kreps, J. (2013). The Log: What every software engineer should know about real-time data's unifying abstraction. https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying
