# üö¶ Rate Limiting (Limita√ß√£o de Taxa)

## Defini√ß√£o e Vis√£o Geral

Rate Limiting (Limita√ß√£o de Taxa) √© uma t√©cnica usada para controlar a quantidade de solicita√ß√µes que um cliente ou servi√ßo pode fazer a um sistema em um determinado per√≠odo de tempo. Esse conceito √© fundamental para proteger sistemas contra uso excessivo, seja intencional (como ataques de nega√ß√£o de servi√ßo) ou n√£o intencional (como loops infinitos em c√≥digo cliente).

A limita√ß√£o de taxa estabelece limites claros sobre o n√∫mero de a√ß√µes ou solicita√ß√µes permitidas, evitando que qualquer cliente √∫nico consuma recursos de forma desproporcional, garantindo assim uma distribui√ß√£o justa de recursos do sistema e melhorando a disponibilidade e estabilidade para todos os usu√°rios.

## Diagramas

### Fluxo B√°sico de Rate Limiting

```mermaid
flowchart TD
    A[Cliente] --> B{Rate Limiter}
    B -->|Abaixo do limite| C[Servidor]
    B -->|Limite excedido| D[Rejeitar Requisi√ß√£o]
    C --> E[Processar Requisi√ß√£o]
    D --> F[Retornar HTTP 429<br>Too Many Requests]
    
    style B fill:#f96,stroke:#333,stroke-width:2px
```

### Algoritmos Comuns de Rate Limiting

```mermaid
graph TD
    RL[Algoritmos de<br>Rate Limiting] --> TB[Token Bucket]
    RL --> LB[Leaky Bucket]
    RL --> FC[Fixed Window Counter]
    RL --> SW[Sliding Window Log]
    RL --> SWC[Sliding Window Counter]
    
    TB --> TBD[Tokens adicionados<br>em intervalos fixos]
    LB --> LBD[Processa requisi√ß√µes<br>a taxa constante]
    FC --> FCD[Contagem em<br>janelas de tempo fixas]
    SW --> SWD[Rastreia timestamps<br>exatos de requisi√ß√µes]
    SWC --> SWCD[H√≠brido de Fixed Window<br>e Sliding Window]
```

### Implementa√ß√£o Centralizada vs. Distribu√≠da

```mermaid
graph TD
    subgraph Centralizado
        CRL[Rate Limiter Central]
        API1 --> CRL
        API2 --> CRL
        API3 --> CRL
        CRL --> Redis[(Base de<br>Contadores)]
    end
    
    subgraph Distribu√≠do
        API4 --> RL1[Rate Limiter 1]
        API5 --> RL2[Rate Limiter 2]
        API6 --> RL3[Rate Limiter 3]
        RL1 <--> DDS[(Armazenamento<br>Distribu√≠do)]
        RL2 <--> DDS
        RL3 <--> DDS
    end
```

## Casos de Uso

- **APIs p√∫blicas**: Limitar o uso por cliente para garantir disponibilidade para todos
- **Prote√ß√£o contra ataques**: Mitigar ataques DDoS ou brute force
- **Prioriza√ß√£o de tr√°fego**: Favorecer clientes premium sobre planos gratuitos
- **Prote√ß√£o de recursos com custo**: Limitar acesso a recursos externos cobrados por uso
- **Controle de QoS**: Manter qualidade de servi√ßo em per√≠odos de carga alta
- **Rate limiting por usu√°rio**: Evitar que um √∫nico usu√°rio consuma recursos excessivamente
- **Throttling de opera√ß√µes caras**: Limitar opera√ß√µes que consumam muitos recursos computacionais
- **Preven√ß√£o de spam**: Impedir envios repetitivos de conte√∫do

## Exemplos Pr√°ticos

### Implementation do Token Bucket em Python

```python
import time

class TokenBucket:
    def __init__(self, capacity, refill_rate):
        """
        Inicializa um bucket de tokens
        :param capacity: Capacidade m√°xima do bucket
        :param refill_rate: Taxa de reabastecimento em tokens/segundo
        """
        self.capacity = capacity
        self.refill_rate = refill_rate
        self.tokens = capacity  # Come√ßa cheio
        self.last_refill = time.time()
        
    def _refill(self):
        """Reabastece o bucket com tokens baseado no tempo decorrido"""
        now = time.time()
        elapsed = now - self.last_refill
        new_tokens = elapsed * self.refill_rate
        
        if new_tokens > 0:
            self.tokens = min(self.capacity, self.tokens + new_tokens)
            self.last_refill = now
    
    def consume(self, tokens=1):
        """
        Tenta consumir tokens do bucket
        :param tokens: N√∫mero de tokens a consumir
        :return: True se tokens foram consumidos, False caso contr√°rio
        """
        self._refill()
        
        if tokens <= self.tokens:
            self.tokens -= tokens
            return True
        return False


# Exemplo de uso
limiter = TokenBucket(capacity=10, refill_rate=1)  # 10 tokens max, 1 token/s

def handle_request(request_id):
    if limiter.consume():
        print(f"Processando requisi√ß√£o {request_id}")
        # L√≥gica para processar a requisi√ß√£o
        return True
    else:
        print(f"Requisi√ß√£o {request_id} rejeitada: limite excedido")
        return False

# Simula√ß√£o de burst de requisi√ß√µes
for i in range(15):
    handle_request(i)

# Simula√ß√£o de requisi√ß√µes ao longo do tempo
print("\nAguardando reabastecimento...")
time.sleep(5)  # Espera 5 segundos (5 tokens reabastecidos)
print("Ap√≥s 5 segundos:")
for i in range(15, 20):
    handle_request(i)
```

### Rate Limiting com Redis

```python
import redis
import time

class RedisRateLimiter:
    def __init__(self, redis_client, key_prefix, limit, window):
        """
        Implementa rate limiting usando Redis
        :param redis_client: Cliente Redis
        :param key_prefix: Prefixo para chaves (ex: 'ip:', 'user:')
        :param limit: N√∫mero m√°ximo de requisi√ß√µes
        :param window: Janela de tempo em segundos
        """
        self.redis = redis_client
        self.key_prefix = key_prefix
        self.limit = limit
        self.window = window
        
    def is_allowed(self, identifier):
        """
        Verifica se o identificador pode realizar a requisi√ß√£o
        :param identifier: Identificador √∫nico (IP, user_id, etc.)
        :return: True se permitido, False se limite excedido
        """
        key = f"{self.key_prefix}{identifier}"
        current_time = int(time.time())
        window_start = current_time - self.window
        
        # Transa√ß√£o Redis para garantir atomicidade
        pipe = self.redis.pipeline()
        
        # Remove contagens antigas
        pipe.zremrangebyscore(key, 0, window_start)
        # Adiciona requisi√ß√£o atual
        pipe.zadd(key, {current_time: current_time})
        # Conta requisi√ß√µes na janela
        pipe.zcount(key, window_start, current_time)
        # Define expira√ß√£o da chave
        pipe.expire(key, self.window)
        
        _, _, count, _ = pipe.execute()
        
        return count <= self.limit

# Exemplo de uso
redis_client = redis.Redis(host='localhost', port=6379, db=0)
rate_limiter = RedisRateLimiter(
    redis_client=redis_client,
    key_prefix='ip:',
    limit=100,  # 100 requisi√ß√µes
    window=3600  # em uma janela de 1 hora
)

def process_api_request(user_ip, request_data):
    if rate_limiter.is_allowed(user_ip):
        # Processar requisi√ß√£o normalmente
        print(f"Processando requisi√ß√£o de {user_ip}")
        return {"status": "success", "data": "..."}
    else:
        # Rejeitar requisi√ß√£o
        print(f"Limite excedido para {user_ip}")
        return {"status": "error", "message": "Rate limit exceeded. Try again later."}
```

### Implementa√ß√£o em Nginx

```nginx
# Exemplo de configura√ß√£o de rate limiting no Nginx

http {
    # Define uma zona compartilhada chamada "mylimit" com 10MB
    # que armazenar√° o estado de rate limiting
    limit_req_zone $binary_remote_addr zone=mylimit:10m rate=10r/s;
    
    server {
        listen 80;
        server_name api.example.com;
        
        location /api/ {
            # Aplica a zona de rate limiting
            limit_req zone=mylimit burst=20 nodelay;
            
            # Configura√ß√£o normal da rota
            proxy_pass http://backend;
        }
        
        # Taxas diferentes para endpoints diferentes
        location /api/premium/ {
            # Taxa mais alta para usu√°rios premium
            limit_req zone=mylimit burst=100 nodelay;
            proxy_pass http://backend;
        }
        
        # Endpoint espec√≠fico com limita√ß√£o mais restritiva
        location /api/expensive-operation {
            # Limita a 1 requisi√ß√£o por segundo
            limit_req zone=mylimit rate=1r/s;
            proxy_pass http://backend;
        }
    }
}
```

## Algoritmos de Rate Limiting em Detalhes

### Token Bucket

O algoritmo Token Bucket √© um dos mais populares para controle de taxa. Ele consiste em um bucket que armazena tokens virtuais, adicionados a uma taxa constante at√© atingir a capacidade m√°xima. Cada requisi√ß√£o consome um token, e requisi√ß√µes que n√£o encontram tokens dispon√≠veis s√£o rejeitadas ou enfileiradas.

```mermaid
sequenceDiagram
    participant C as Cliente
    participant TB as Token Bucket
    participant S as Servidor
    
    Note over TB: Bucket tem 5 tokens<br>(capacidade=5, taxa=1/s)
    
    C->>TB: Requisi√ß√£o 1
    TB->>TB: Consome 1 token (4 restantes)
    TB->>S: Encaminha requisi√ß√£o
    
    C->>TB: Requisi√ß√£o 2
    TB->>TB: Consome 1 token (3 restantes)
    TB->>S: Encaminha requisi√ß√£o
    
    C->>TB: Requisi√ß√£o 3
    TB->>TB: Consome 1 token (2 restantes)
    TB->>S: Encaminha requisi√ß√£o
    
    C->>TB: Requisi√ß√£o 4
    TB->>TB: Consome 1 token (1 restante)
    TB->>S: Encaminha requisi√ß√£o
    
    C->>TB: Requisi√ß√£o 5
    TB->>TB: Consome 1 token (0 restantes)
    TB->>S: Encaminha requisi√ß√£o
    
    C->>TB: Requisi√ß√£o 6
    TB->>C: Rejeita (sem tokens)
    
    Note over TB: Ap√≥s 2 segundos,<br>2 tokens adicionados
    
    C->>TB: Requisi√ß√£o 7
    TB->>TB: Consome 1 token (1 restante)
    TB->>S: Encaminha requisi√ß√£o
```

### Leaky Bucket

O Leaky Bucket (Balde Furado) √© similar ao Token Bucket, mas controla a taxa de sa√≠da das requisi√ß√µes, n√£o a entrada. As requisi√ß√µes s√£o enfileiradas em um buffer e processadas a uma taxa constante. Se o buffer estiver cheio, novas requisi√ß√µes s√£o descartadas.

### Fixed Window Counter

O Fixed Window Counter divide o tempo em janelas fixas (por exemplo, 1 minuto) e permite um n√∫mero m√°ximo de requisi√ß√µes em cada janela. Este algoritmo √© simples de implementar, mas pode permitir picos de tr√°fego nas bordas das janelas.

```mermaid
graph LR
    subgraph "Janelas de 1 minuto"
        W1[12:00-12:01<br>100 req/min]
        W2[12:01-12:02<br>100 req/min]
        W3[12:02-12:03<br>100 req/min]
    end
    
    subgraph "Problema de Borda"
        B1[99 req no final<br>da janela 1]
        B2[99 req no in√≠cio<br>da janela 2]
        B1 --- B2
        
        Note[198 req em<br>poucos segundos]
    end
```

### Sliding Window Log

O Sliding Window Log mant√©m um registro com timestamp de cada requisi√ß√£o. Para verificar se uma nova requisi√ß√£o √© permitida, conta-se o n√∫mero de entradas no registro dentro da janela de tempo. Este m√©todo √© preciso, mas pode consumir muita mem√≥ria para aplica√ß√µes com alto tr√°fego.

### Sliding Window Counter

O Sliding Window Counter combina as abordagens de Fixed Window e Sliding Window Log. Ele usa dois contadores de janelas fixas adjacentes e calcula uma m√©dia ponderada com base no quanto da janela atual j√° passou.

## Pr√≥s e Contras

### Pr√≥s
- **Prote√ß√£o do sistema**: Previne sobrecarga por excesso de requisi√ß√µes
- **Justi√ßa na distribui√ß√£o de recursos**: Impede que usu√°rios √∫nicos monopolizem o sistema
- **Mitiga√ß√£o de ataques**: Reduz o impacto de ataques de nega√ß√£o de servi√ßo
- **Controle de custos**: Limita uso de servi√ßos externos pagos por consumo
- **QoS previs√≠vel**: Garante tempos de resposta consistentes
- **Prioriza√ß√£o de tr√°fego**: Permite diferenciar n√≠veis de servi√ßo
- **Detec√ß√£o de anomalias**: Identifica padr√µes de uso anormais
- **Facilita planejamento de capacidade**: Torna o consumo de recursos mais previs√≠vel

### Contras
- **Complexidade**: Adiciona mais uma camada ao sistema
- **Falsos positivos**: Pode bloquear tr√°fego leg√≠timo em picos
- **Experi√™ncia do usu√°rio**: Clientes podem enfrentar falhas tempor√°rias
- **Configura√ß√£o delicada**: Definir limites apropriados pode ser desafiador
- **Distribui√ß√£o complexa**: Em sistemas distribu√≠dos, sincroniza√ß√£o pode ser dif√≠cil
- **Overhead**: Adiciona lat√™ncia √†s requisi√ß√µes
- **Recurso adicional**: Requer infraestrutura e manuten√ß√£o separadas

## Melhores Pr√°ticas

1. **Comunique claramente os limites**: Informe aos usu√°rios sobre as limita√ß√µes de taxa atrav√©s de documenta√ß√£o e cabe√ßalhos HTTP.

2. **Use cabe√ßalhos padr√£o**: Retorne cabe√ßalhos como `X-RateLimit-Limit`, `X-RateLimit-Remaining` e `X-RateLimit-Reset` para APIs.

3. **Implemente backoff exponencial**: Oriente clientes a usar espera exponencial antes de tentar novamente.

4. **Defina limites granulares**: Adapte os limites por endpoint, tipo de usu√°rio, ou import√¢ncia da opera√ß√£o.

5. **Monitore e ajuste**: Monitore constantemente os padr√µes de uso e ajuste limites conforme necess√°rio.

6. **Use queue para requisi√ß√µes excedentes**: Em vez de rejeitar imediatamente, considere enfileirar.

7. **Implementa√ß√£o centralizada**: Use uma solu√ß√£o centralizada para consist√™ncia em sistemas distribu√≠dos.

8. **Considere limites por IP e por usu√°rio**: Combine diferentes identificadores para melhor seguran√ßa.

9. **Teste extensivamente**: Simule cen√°rios de alta carga para verificar o comportamento do rate limiter.

10. **Planeje a degrada√ß√£o gradual**: Reduza a qualidade de servi√ßo progressivamente em vez de falhar abruptamente.

## Implementa√ß√µes em Diferentes N√≠veis

### Rate Limiting por Camada

```mermaid
graph TD
    subgraph "Camadas de Rate Limiting"
        L1[N√≠vel de Infraestrutura]
        L2[N√≠vel de API Gateway]
        L3[N√≠vel de Servi√ßo]
        L4[N√≠vel de Banco de Dados]
        
        L1 --> L2 --> L3 --> L4
    end
    
    subgraph "Exemplos"
        L1 --- E1[Firewall, CDN]
        L2 --- E2[Kong, AWS API Gateway]
        L3 --- E3[C√≥digo da aplica√ß√£o]
        L4 --- E4[Throttling de conex√µes DB]
    end
```

### Limita√ß√£o por Cliente
- **Por IP**: Limita requisi√ß√µes baseado no endere√ßo IP
- **Por usu√°rio**: Limita baseado no ID de usu√°rio autenticado
- **Por API key**: Limita baseado na chave de API fornecida
- **Por conta/organiza√ß√£o**: Limita agregando uso de m√∫ltiplos usu√°rios

### Cabe√ßalhos HTTP para Rate Limiting

```
HTTP/1.1 429 Too Many Requests
Content-Type: application/json
X-RateLimit-Limit: 100
X-RateLimit-Remaining: 0
X-RateLimit-Reset: 1616180088
Retry-After: 60

{
  "error": "rate_limit_exceeded",
  "message": "You have exceeded the rate limit of 100 requests per hour.",
  "retry_after": 60
}
```

## Ferramentas e Implementa√ß√µes Populares

### Software e Bibliotecas
- **Redis Cell**: M√≥dulo Redis com implementa√ß√£o de rate limiting
- **Nginx Rate Limiting**: M√≥dulos nativos do Nginx para limita√ß√£o
- **HAProxy Rate Limiting**: Configura√ß√µes para controle de taxa
- **Guava RateLimiter**: Biblioteca Java para rate limiting
- **Resilience4j**: Framework Java com suporte a rate limiting
- **Throttled**: Biblioteca Go para rate limiting
- **Flask-Limiter**: Extens√£o Flask para Python
- **Express Rate Limit**: Middleware para Node.js
- **AWS WAF**: Rate limiting em n√≠vel de firewall de aplica√ß√£o
- **Azure API Management**: Pol√≠ticas de rate limiting

### Servi√ßos em Nuvem
- **Cloudflare Rate Limiting**: Prote√ß√£o em n√≠vel de CDN
- **AWS API Gateway**: Throttling e limites de rajada configur√°veis
- **Google Cloud Armor**: Prote√ß√£o contra abusos e DDoS
- **Azure Front Door**: Limita√ß√£o em n√≠vel de WAF
- **Akamai API Gateway**: Controle granular de taxa de API

## Considera√ß√µes para Arquiteturas Distribu√≠das

```mermaid
graph TD
    subgraph Global
        CRL[Rate Limiter Centralizado]
    end
    
    subgraph "Regi√£o 1"
        RL1[Rate Limiter Local]
        S1[Servi√ßo 1] --> RL1
        RL1 --> CRL
    end
    
    subgraph "Regi√£o 2"
        RL2[Rate Limiter Local]
        S2[Servi√ßo 2] --> RL2
        RL2 --> CRL
    end
    
    subgraph "Regi√£o 3"
        RL3[Rate Limiter Local]
        S3[Servi√ßo 3] --> RL3
        RL3 --> CRL
    end
```

### Estrat√©gias para Sistemas Distribu√≠dos
1. **Sincroniza√ß√£o peri√≥dica**: Os n√≥s sincronizam contadores em intervalos regulares
2. **Armazenamento centralizado**: Todos os n√≥s consultam uma store distribu√≠da
3. **Particionamento**: Cada n√≥ gerencia um subconjunto de clientes/tokens
4. **Rate limiting aproximado**: T√©cnicas probabil√≠sticas como Count-Min Sketch
5. **Rate limiting em camadas**: Combinar limita√ß√£o local e global

## Refer√™ncias

- Kleppmann, M. (2017). Designing Data-Intensive Applications. O'Reilly Media.
- Nygard, M. T. (2018). Release It! (2nd ed.). Pragmatic Bookshelf.
- Fielding, R. T. (2000). Architectural Styles and the Design of Network-based Software Architectures. University of California, Irvine.
- Metriks, E. (2022). HTTP Rate Limiter Algorithms Explained. Medium Article.
- Richardson, C. (2018). Microservices Patterns. Manning Publications.
- Kong. (2023). Rate Limiting Documentation. https://docs.konghq.com/hub/kong-inc/rate-limiting/
- Nginx. (2023). Rate Limiting. https://www.nginx.com/blog/rate-limiting-nginx/
- AWS. (2023). API Gateway Request Throttling. https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-request-throttling.html
- Google Cloud. (2023). Rate Limiting. https://cloud.google.com/solutions/rate-limiting-strategies-techniques
- Redis. (2023). Rate Limiting with Redis. https://redis.io/commands/incr
